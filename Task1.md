æˆ‘å°†ä¸ºä½ ç”Ÿæˆ**ä¸‰ä¸ªç‹¬ç«‹çš„å¼€å‘æ¸…å•ï¼ˆLayer 1/2/3ï¼‰**ï¼Œæ¯ä¸ªå¯¹åº”é¡¹ç›®çš„ä¸€å±‚æ¶æ„ã€‚è¿™æ˜¯**ç¬¬ä¸€ä¸ªæ¸…å•ï¼šæ”»å‡»å±‚ï¼ˆLayer 1ï¼‰**ï¼Œ

---

# ğŸ¯ Kimi Code å·¥ä½œåˆ—è¡¨æ–‡ä»¶ #1ï¼šæ”»å‡»å±‚ (Adversarial Attacks Layer)

**ç›®æ ‡**ï¼šæ„å»ºèƒ½ç”Ÿæˆç”Ÿç†å¯ä¿¡å¯¹æŠ—æ ·æœ¬çš„æ”»å‡»ç³»ç»Ÿï¼ˆFGSMåŸºç¡€ + SAPæ ¸å¿ƒï¼‰  
**æŠ€æœ¯æ ˆ**ï¼šPyTorch 2.0+ | torchattacks (å‚è€ƒ) | neurokit2 | matplotlib  
**äº¤ä»˜ç‰©**ï¼š`attacks/` æ¨¡å— + å¯è§†åŒ–æŠ¥å‘Š + å¯¹æŠ—æ ·æœ¬æ•°æ®é›†  

---

## æ¨¡å—1ï¼šæ•°æ®åŸºç¡€è®¾æ–½ (Data Pipeline)

### Task 1.1 MIT-BIH æ•°æ®åŠ è½½å™¨
**æ–‡ä»¶**ï¼š`data/mitbih_loader.py`  
**è¾“å…¥**ï¼šKaggleä¸‹è½½çš„ `mitbih_train.csv` / `mitbih_test.csv`ï¼ˆåŒ…å«187é‡‡æ ·ç‚¹+æ ‡ç­¾ï¼‰  
**è¾“å‡º**ï¼š`torch.utils.data.Dataset` å­ç±»  

**éªŒæ”¶æ ‡å‡†**ï¼š
```python
# å¿…é¡»æ”¯æŒçš„API
train_set = MITBIHDataset(csv_path='mitbih_train.csv', transform='normalize')
loader = DataLoader(train_set, batch_size=32)
x, y = next(iter(loader))  # x.shape = [32, 1, 187], y.shape = [32]
```

**å…³é”®ä»£ç è¦æ±‚**ï¼š
- å½’ä¸€åŒ–ï¼šMin-Maxåˆ° `[0, 1]`ï¼ˆä¸Hanè®ºæ–‡ä¸€è‡´ï¼‰
- æ ‡ç­¾æ˜ å°„ï¼šMIT-BIHçš„5ç±»ï¼ˆN,S,V,F,Qï¼‰è½¬ä¸º0-4æ•´æ•°
- é¢„åŠ è½½ï¼šæ”¯æŒ`preload=True`å°†å…¨æ•°æ®è½½å…¥å†…å­˜ï¼ˆMIT-BIHå¾ˆå°ï¼Œåªæœ‰10ä¸‡æ¡ï¼‰

---

## æ¨¡å—2ï¼šåŸºçº¿åˆ†ç±»æ¨¡å‹ (Victim Model)

### Task 1.2 1D-CNN åŸºçº¿æ¨¡å‹
**æ–‡ä»¶**ï¼š`models/ecg_cnn.py`  
**æ¶æ„**ï¼ˆä¸Ma & Liang 2022ä¸€è‡´ä»¥ä¾¿å¯¹æ¯”ï¼‰ï¼š
```python
class ECG_CNN(nn.Module):
    def __init__(self, num_classes=5):
        super().__init__()
        # 4 Conv Blocks: Conv1d -> BN -> ReLU -> MaxPool
        # Block 1: in=1, out=16, kernel=7, stride=1, padding=3
        # Block 2: in=16, out=32, kernel=5, stride=1, padding=2  
        # Block 3: in=32, out=64, kernel=3, stride=1, padding=1
        # Block 4: in=64, out=128, kernel=3, stride=1, padding=1
        # GlobalAvgPool -> FC(128->64) -> FC(64->5)
```

**éªŒæ”¶æ ‡å‡†**ï¼š
- å‚æ•°é‡ï¼š< 500Kï¼ˆ5060æ˜¾å¡å‹å¥½ï¼‰
- Clean Accuracyï¼šåœ¨æµ‹è¯•é›†ä¸Š **â‰¥ 91%**ï¼ˆMIT-BIH baselineè¦æ±‚ï¼‰
- ä¿å­˜è·¯å¾„ï¼š`checkpoints/clean_model.pth`

---

## æ¨¡å—3ï¼šæ”»å‡»ç®—æ³•å®ç° (Core Algorithms)

### Task 1.3 åŸºç¡€æ”»å‡»åŸºç±»
**æ–‡ä»¶**ï¼š`attacks/base_attack.py`  
**æŠ½è±¡æ¥å£**ï¼š
```python
class BaseAttack(ABC):
    def __init__(self, model, device, eps=0.01):
        self.model = model.eval()
        self.device = device
        self.eps = eps
    
    @abstractmethod
    def generate(self, x, y=None, targeted=False):
        """è¿”å›å¯¹æŠ—æ ·æœ¬ x_advï¼Œä¸xåŒshape"""
        pass
    
    def clip(self, x_adv, x_orig):
        """æŠ•å½±å›epsilonçƒå’Œ[0,1]èŒƒå›´"""
        return torch.clamp(x_adv, x_orig-self.eps, x_orig+self.eps).clamp(0,1)
```

### Task 1.4 FGSM å®ç°ï¼ˆçƒ­èº«éªŒè¯ï¼‰
**æ–‡ä»¶**ï¼š`attacks/fgsm.py`  
**å…¬å¼**ï¼š`x_adv = x + Îµ * sign(âˆ‡_x L(f(x), y))`  
**ç‰¹æ®Šè¦æ±‚**ï¼š
- æ”¯æŒ`targeted`æ¨¡å¼ï¼ˆè‹¥targeted=Trueï¼Œåˆ™æ¢¯åº¦å‡è€ŒéåŠ ï¼‰
- å•æ­¥å®Œæˆï¼Œæ— è¿­ä»£

**éªŒæ”¶æµ‹è¯•**ï¼š
```python
# åœ¨æµ‹è¯•é›†ä¸Šè¿è¡Œ
attacker = FGSM(model, eps=0.01)
x_adv = attacker.generate(x, y)
# éªŒè¯ï¼šæ¨¡å‹å‡†ç¡®ç‡åº”ä»91%é™è‡³<20%
```

### Task 1.5 PGD å®ç°ï¼ˆæ ‡å‡†ç™½ç›’æ”»å‡»ï¼‰
**æ–‡ä»¶**ï¼š`attacks/pgd.py`  
**å‚æ•°**ï¼š
- `num_steps`: è¿­ä»£æ­¥æ•°ï¼ˆé»˜è®¤20ï¼Œè¯„ä¼°æ—¶ç”¨100ï¼‰
- `alpha`: æ­¥é•¿ï¼ˆé»˜è®¤0.002ï¼Œå³eps/5ï¼‰
- `random_start`: Trueï¼ˆéšæœºåˆå§‹åŒ–åœ¨epsilonçƒå†…ï¼‰

**ç®—æ³•æµç¨‹**ï¼š
```python
x_adv = x + random_noise(-eps, eps)
for t in range(num_steps):
    grad = compute_gradient(loss(f(x_adv), y), x_adv)
    x_adv = x_adv + alpha * sign(grad)
    x_adv = clip(x_adv, x, eps)  # æŠ•å½±å›Linfçƒ
```

### Task 1.6 SAP å¹³æ»‘æ”»å‡»ï¼ˆæ ¸å¿ƒåˆ›æ–°å¤ç°ï¼‰
**æ–‡ä»¶**ï¼š`attacks/sap.py`  
**è®ºæ–‡æ¥æº**ï¼šHan et al. Nature Medicine 2020  
**å…³é”®åŒºåˆ«**ï¼šä¼ ç»ŸPGDä¼˜åŒ–`x_adv`ï¼ŒSAPä¼˜åŒ–**å¹³æ»‘æ‰°åŠ¨å‚æ•°Î¸**ï¼Œç„¶åå·ç§¯

**å®ç°æ­¥éª¤**ï¼š

1. **å¤šå°ºåº¦é«˜æ–¯æ ¸å®šä¹‰**ï¼ˆåœ¨`__init__`ä¸­é¢„è®¡ç®—ï¼‰ï¼š
```python
self.kernel_sizes = [5, 7, 11, 15, 19]
self.sigmas = [1.0, 3.0, 5.0, 7.0, 10.0]
self.kernels = [self._gaussian_kernel(s, sig) for s, sig in zip(sizes, sigmas)]
```

2. **å‰å‘ç”Ÿæˆå‡½æ•°**ï¼š
```python
def generate(self, x, y, num_steps=40):
    # 1. åˆå§‹åŒ–thetaï¼ˆå¯å­¦ä¹ æ‰°åŠ¨ï¼‰
    theta = torch.zeros_like(x, requires_grad=True)
    
    # 2. å¯é€‰ï¼šç”¨PGDåˆå§‹åŒ–thetaï¼ˆåŠ é€Ÿæ”¶æ•›ï¼‰
    with torch.no_grad():
        init_perturb = self._pgd_init(x, y)  # å¿«é€Ÿ10æ­¥PGD
        theta.data = init_perturb
    
    optimizer = torch.optim.Adam([theta], lr=0.01)
    
    for step in range(num_steps):
        optimizer.zero_grad()
        
        # 3. åº”ç”¨å¹³æ»‘ï¼šx_adv = x + mean(conv(theta, kernel_i))
        perturb_smooth = torch.zeros_like(x)
        for k in self.kernels:
            perturb_smooth += F.conv1d(theta, k.to(x.device), padding='same')
        perturb_smooth /= len(self.kernels)
        
        x_adv = x + perturb_smooth
        x_adv = torch.clamp(x_adv, 0, 1)
        
        # 4. è®¡ç®—æŸå¤±å¹¶åå‘ä¼ æ’­åˆ°theta
        loss = -F.cross_entropy(self.model(x_adv), y)  # æœ€å¤§åŒ–æŸå¤±
        loss.backward()
        optimizer.step()
        
        # 5. çº¦æŸthetaåœ¨epsèŒƒå›´å†…ï¼ˆLinfçº¦æŸï¼‰
        with torch.no_grad():
            theta.data = torch.clamp(theta.data, -self.eps, self.eps)
    
    return x + self._apply_smoothing(theta).detach()
```

3. **å¹³æ»‘åº¦è¯„ä¼°å‡½æ•°**ï¼ˆå†…éƒ¨éªŒè¯ç”¨ï¼‰ï¼š
```python
def smoothness_metric(delta):
    """delta: æ‰°åŠ¨ä¿¡å· [1, 1, 187]"""
    diff = delta[0, 0, 1:] - delta[0, 0, :-1]
    return torch.var(diff).item()  # ç›®æ ‡ï¼š<0.001ï¼ˆéå¸¸å¹³æ»‘ï¼‰
```

**éªŒæ”¶æ ‡å‡†**ï¼š
- å¯¹æŠ—æˆåŠŸç‡ï¼ˆASRï¼‰> 80%
- å¹³æ»‘åº¦ï¼ˆvariance of diffï¼‰< PGDæ”»å‡»çš„10%
- äººç±»è‚‰çœ¼æ— æ³•åŒºåˆ†ï¼ˆé€šè¿‡åç»­å¯è§†åŒ–éªŒè¯ï¼‰

---

## æ¨¡å—4ï¼šæ”»å‡»è¯„ä¼°ç³»ç»Ÿ (Evaluation)

### Task 1.7 æ”»å‡»æŒ‡æ ‡è®¡ç®—å™¨
**æ–‡ä»¶**ï¼š`evaluation/attack_metrics.py`  
**å¿…é¡»å®ç°çš„æŒ‡æ ‡**ï¼š

| æŒ‡æ ‡ | å‡½æ•°å | è®¡ç®—å…¬å¼ | ç›®æ ‡å€¼ |
|------|--------|----------|--------|
| ASR | `attack_success_rate()` | è¢«è¯¯åˆ†ç±»çš„å¯¹æŠ—æ ·æœ¬æ¯”ä¾‹ | >80% |
| L2æ‰°åŠ¨ | `perturbation_l2()` | `||x_adv - x||_2 / sqrt(dim)` | <0.05 |
| Linfæ‰°åŠ¨ | `perturbation_linf()` | `max(abs(x_adv - x))` | <=eps (0.01) |
| SNR | `signal_noise_ratio()` | `20*log10(std(x)/std(delta))` | >20dB |
| å¹³æ»‘åº¦ | `smoothness()` | `var(diff(delta))` | <1e-4 |

### Task 1.8 å¯è§†åŒ–å·¥å…·
**æ–‡ä»¶**ï¼š`evaluation/visualizer.py`  
**å¿…é¡»ç”Ÿæˆçš„å›¾è¡¨**ï¼š

1. **æ³¢å½¢å¯¹æ¯”å›¾**ï¼ˆå‚è€ƒHanè®ºæ–‡Fig.1ï¼‰ï¼š
   - å­å›¾1ï¼šåŸå§‹ECGï¼ˆè“è‰²ï¼‰+ å¯¹æŠ—ECGï¼ˆçº¢è‰²åŠé€æ˜å åŠ ï¼‰
   - å­å›¾2ï¼šæ‰°åŠ¨æ³¢å½¢ï¼ˆå•ç‹¬æ˜¾ç¤ºï¼ŒéªŒè¯å¹³æ»‘æ€§ï¼‰
   
2. **æ”»å‡»å¼ºåº¦æ›²çº¿**ï¼š
   - Xè½´ï¼šepsilon (0~0.05)
   - Yè½´ï¼šæ¨¡å‹å‡†ç¡®ç‡
   - å¯¹æ¯”æ›²çº¿ï¼šClean vs FGSM vs PGD vs SAP

3. **é¢‘è°±åˆ†æ**ï¼ˆéªŒè¯SAPçš„å¹³æ»‘æ€§ï¼‰ï¼š
   - ä½¿ç”¨FFTå¯¹æ¯”PGDå’ŒSAPæ‰°åŠ¨çš„é¢‘è°±ï¼ˆSAPé«˜é¢‘æˆåˆ†åº”æ›´å°‘ï¼‰

**è¾“å‡ºæ ¼å¼**ï¼š`results/figures/attack_*.png`ï¼Œ300dpiï¼Œé€‚åˆè®ºæ–‡æ’å…¥

---

## æ¨¡å—5ï¼šé›†æˆä¸æ•°æ®ç”Ÿæˆ

### Task 1.9 å¯¹æŠ—æ ·æœ¬æ•°æ®é›†ç”Ÿæˆå™¨
**æ–‡ä»¶**ï¼š`generate_adversarial_dataset.py`  
**åŠŸèƒ½**ï¼š
- åŠ è½½è®­ç»ƒå¥½çš„Cleanæ¨¡å‹
- å¯¹æµ‹è¯•é›†ç”Ÿæˆä¸‰ç§æ”»å‡»æ ·æœ¬ï¼š
  - `test_pgd.pt` (eps=0.01, 20-steps)
  - `test_sap.pt` (eps=0.01, 40-steps, å¤šå°ºåº¦é«˜æ–¯)
  - `test_fgsm.pt` (eps=0.01)
- ä¿å­˜æ ¼å¼ï¼š`torch.save({'x_adv': tensor, 'y': tensor, 'x_orig': tensor}, file)`

**ç”¨é€”**ï¼šè¿™äº›`.pt`æ–‡ä»¶å°†ç›´æ¥ç”¨äº**Layer 2ï¼ˆé˜²å¾¡å±‚ï¼‰**çš„å¯¹æŠ—è®­ç»ƒ

---

## ğŸ Layer 1 äº¤ä»˜æ£€æŸ¥æ¸…å•

å®Œæˆä»¥ä¸‹æ£€æŸ¥é¡¹åï¼ŒLayer 1ç»“æŸï¼Œå¯è¿›å…¥Layer 2ï¼š

- [ ] `python train_baseline.py` è¿è¡Œåæµ‹è¯•é›†acc â‰¥ 91%
- [ ] `python attacks/sap.py --test` èƒ½ç”Ÿæˆå•æ¡å¯¹æŠ—æ ·æœ¬å¹¶æ˜¾ç¤ºå¹³æ»‘åº¦<1e-4
- [ ] `python evaluate_attacks.py` è¾“å‡ºASRè¡¨æ ¼ï¼ˆPGD vs SAPå¯¹æ¯”ï¼‰
- [ ] `results/` ç›®å½•åŒ…å«è‡³å°‘3å¼ å¯è§†åŒ–å›¾ç‰‡ï¼ˆæ³¢å½¢å¯¹æ¯”ã€å‡†ç¡®ç‡æ›²çº¿ã€æ‰°åŠ¨å¹³æ»‘åº¦ï¼‰
- [ ] `data/adversarial/` ç›®å½•åŒ…å«ç”Ÿæˆçš„`.pt`å¯¹æŠ—æ ·æœ¬æ–‡ä»¶ï¼ˆä¾›åç»­é˜²å¾¡è®­ç»ƒä½¿ç”¨ï¼‰

---

è¯·å›å¤**"ç»§ç»­"**ï¼Œæˆ‘å°†æä¾›**Layer 2ï¼šé˜²å¾¡å±‚**ï¼ˆå¯¹æŠ—è®­ç»ƒ + NSRæ­£åˆ™åŒ–å®ç°ï¼‰çš„è¯¦ç»†å·¥ä½œåˆ—è¡¨ã€‚