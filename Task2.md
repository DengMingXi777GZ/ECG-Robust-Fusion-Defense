åŸºäº**Layer 1å·²å®Œæˆ**çš„ç°çŠ¶ï¼ˆåŸºçº¿æ¨¡å‹93.43%å‡†ç¡®ç‡ï¼Œeps=0.05æ—¶PGD ASR=88.58%ï¼‰ï¼Œä»¥ä¸‹æ˜¯**Layer 2ï¼šé˜²å¾¡å±‚ï¼ˆDefense Layerï¼‰**çš„å®Œæ•´ä»»åŠ¡æ¸…å•ã€‚

---

# ğŸ›¡ï¸ Kimi Code å·¥ä½œåˆ—è¡¨æ–‡ä»¶ #2ï¼šé˜²å¾¡å±‚ (Defense & Robust Training Layer)

**å‰ç½®ä¾èµ–**ï¼šå¿…é¡»å®ŒæˆLayer 1ï¼ˆ`checkpoints/clean_model.pth` + `data/adversarial/`ä¸‹çš„å¯¹æŠ—æ ·æœ¬ï¼‰  
**æ ¸å¿ƒç›®æ ‡**ï¼šæ„å»ºèƒ½æŠµæŠ—eps=0.05æ”»å‡»çš„é²æ£’æ¨¡å‹ï¼ˆå¯¹æŠ—è®­ç»ƒ + NSRæ­£åˆ™åŒ–ï¼‰  
**å…³é”®è®¾å®š**ï¼šåŸºäºLayer 1å‘ç°ï¼Œä½¿ç”¨**eps=0.05**ä½œä¸ºè®­ç»ƒå’Œè¯„ä¼°æ ‡å‡†ï¼ˆPGD-40 ASR=88.58%ï¼Œæœ‰æ•ˆä¸”ç”Ÿç†å¯ä¿¡ï¼‰

---

## ğŸ“¥ ç»§æ‰¿èµ„äº§æ¸…å•ï¼ˆæ¥è‡ªLayer 1ï¼‰

**å¿…é¡»å­˜åœ¨çš„æ–‡ä»¶**ï¼ˆLayer 2å¯åŠ¨å‰æ£€æŸ¥ï¼‰ï¼š
```bash
checkpoints/
â””â”€â”€ clean_model.pth              # åŸºçº¿æ¨¡å‹ (93.43% acc)

data/adversarial/                # Layer 1ç”Ÿæˆçš„å¯¹æŠ—æ ·æœ¬
â”œâ”€â”€ test_fgsm_eps005.pt          # éœ€é‡æ–°ç”Ÿæˆï¼Œeps=0.05
â”œâ”€â”€ test_pgd_eps005.pt           # ç”¨äºè¯„ä¼°
â””â”€â”€ test_sap_eps005.pt           # ç”¨äºè¯„ä¼°

attacks/                         # Layer 1çš„æ”»å‡»æ¨¡å—ï¼ˆç›´æ¥å¤ç”¨ï¼‰
â”œâ”€â”€ base_attack.py
â”œâ”€â”€ pgd.py                       # å…³é”®ï¼šPGD(eps=0.05, steps=40)
â””â”€â”€ sap.py                       # å…³é”®ï¼šSAP(eps=0.05, steps=40)
```

**Layer 1å…³é”®ç»“è®º**ï¼š
- æ¨¡å‹åœ¨`eps=0.01`æ—¶ASRè¿‡ä½(1.97%)ï¼Œä½†åœ¨`eps=0.05`æ—¶ASR=88.58%ï¼ˆæœ‰æ•ˆæ”»å‡»ï¼‰
- å› æ­¤Layer 2æ‰€æœ‰å¯¹æŠ—è®­ç»ƒä½¿ç”¨**eps=0.05**ä½œä¸ºæ‰°åŠ¨é¢„ç®—

---

## æ¨¡å—6ï¼šå¯¹æŠ—è®­ç»ƒåŸºç¡€è®¾æ–½ (Adversarial Training Core)

### Task 2.1 å¯¹æŠ—è®­ç»ƒæ•°æ®é›†ç”Ÿæˆå™¨ï¼ˆåŠ¨æ€ç”Ÿæˆï¼‰
**æ–‡ä»¶**ï¼š`defense/adv_trainer.py`ä¸­çš„`AdversarialDataset`ç±»  
**ç»§æ‰¿è¦æ±‚**ï¼šä½¿ç”¨Layer 1çš„PGD/SAPå®ç°ï¼Œä½†å‚æ•°æ”¹ä¸ºeps=0.05

```python
class AdversarialDataset(Dataset):
    def __init__(self, clean_dataset, model, attack_method='pgd', 
                 eps=0.05, steps=40, alpha=0.0125):  # alpha=eps/4
        """
        åŠ¨æ€ç”Ÿæˆå¯¹æŠ—æ ·æœ¬ï¼ŒèŠ‚çœå†…å­˜
        å…³é”®ï¼šä½¿ç”¨Layer 1éªŒè¯æœ‰æ•ˆçš„eps=0.05å‚æ•°
        """
        self.clean_data = clean_dataset
        self.model = model
        # ç›´æ¥å¤ç”¨Layer 1çš„attacksæ¨¡å—
        if attack_method == 'pgd':
            self.attacker = PGD(model, eps=eps, steps=steps, alpha=alpha)
        elif attack_method == 'sap':
            self.attacker = SAP(model, eps=eps, steps=steps)
    
    def __getitem__(self, idx):
        x, y = self.clean_data[idx]
        # å…³é”®ï¼šæ¯æ¬¡getitemç”Ÿæˆæ–°çš„å¯¹æŠ—æ ·æœ¬ï¼ˆé¿å…è¿‡æ‹Ÿåˆåˆ°å›ºå®šå™ªå£°ï¼‰
        with torch.enable_grad():  # ç¡®ä¿æ¢¯åº¦å¼€å¯
            x_adv = self.attacker.generate(x.unsqueeze(0), 
                                           y.unsqueeze(0)).squeeze(0)
        return x, x_adv, y
```

### Task 2.2 é‡æ–°ç”Ÿæˆeps=0.05çš„å¯¹æŠ—æ ·æœ¬æ•°æ®é›†
**å‘½ä»¤**ï¼ˆåŸºäºLayer 1çš„generateè„šæœ¬ï¼Œä¿®æ”¹epsï¼‰ï¼š
```bash
python generate_adversarial_dataset.py \
    --checkpoint checkpoints/clean_model.pth \
    --eps 0.05 \
    --pgd-steps 40 \
    --sap-steps 40 \
    --output-dir data/adversarial/eps005/
```

**é¢„æœŸäº§å‡º**ï¼š
```
data/adversarial/eps005/
â”œâ”€â”€ test_fgsm.pt      (21,892æ¡, eps=0.05, ASR~8-30%)
â”œâ”€â”€ test_pgd.pt       (21,892æ¡, eps=0.05, ASR~88%) 
â””â”€â”€ test_sap.pt       (21,892æ¡, eps=0.05, ASR~85%)
```

---

## æ¨¡å—7ï¼šå¯¹æŠ—è®­ç»ƒå®ç° (Standard AT)

### Task 2.3 æ ‡å‡†å¯¹æŠ—è®­ç»ƒ (Madry's AT)
**æ–‡ä»¶**ï¼š`defense/train_standard_at.py`  
**æ ¸å¿ƒé€»è¾‘**ï¼šMin-Maxä¼˜åŒ–ï¼Œæ··åˆCleanå’ŒAdvæ ·æœ¬

```python
def train_epoch(model, loader, optimizer, criterion, eps=0.05):
    model.train()
    total_loss = 0
    
    for x_clean, y in loader:
        x_clean, y = x_clean.cuda(), y.cuda()
        
        # 1. ç”Ÿæˆå¯¹æŠ—æ ·æœ¬ï¼ˆä½¿ç”¨å½“å‰æ¨¡å‹çŠ¶æ€ï¼‰
        attacker = PGD(model, eps=eps, steps=10, alpha=eps/4)  # è®­ç»ƒç”¨10æ­¥
        x_adv = attacker.generate(x_clean, y)
        
        # 2. æ··åˆæ•°æ®ï¼ˆMadryæ ‡å‡†åšæ³•ï¼šå„50%ï¼‰
        x_mixed = torch.cat([x_clean, x_adv], dim=0)
        y_mixed = torch.cat([y, y], dim=0)
        
        # 3. å‰å‘ä¸æŸå¤±
        output = model(x_mixed)
        loss = criterion(output, y_mixed)
        
        # 4. åå‘ä¼ æ’­
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
    
    return total_loss / len(loader)
```

**è¶…å‚æ•°é…ç½®**ï¼ˆåŸºäºMa & Liang 2022ï¼‰ï¼š
- Epochs: 50
- Optimizer: Adam, lr=0.001 (å‰5epoch warmupåªç”¨cleanæ•°æ®)
- Epsilon: **0.05**ï¼ˆåŸºäºLayer 1ç»“è®ºï¼‰
- Attack steps: 10ï¼ˆè®­ç»ƒæ—¶ï¼Œæ¯”è¯„ä¼°æ—¶çš„40æ­¥å¼±ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰
- Batch size: 256

**éªŒæ”¶æ ‡å‡†**ï¼š
- Clean Accuracy â‰¥ 88%ï¼ˆå…è®¸æ¯”93.43%ä¸‹é™5%ä»¥å†…ï¼‰
- PGD-20 (eps=0.05) Accuracy â‰¥ 60%ï¼ˆé²æ£’æ€§æå‡ï¼‰
- æ¨¡å‹ä¿å­˜ï¼š`checkpoints/adv_standard_at.pth`

---

## æ¨¡å—8ï¼šNSRæ­£åˆ™åŒ–å®ç° (æ ¸å¿ƒåˆ›æ–°)

### Task 2.4 NSRæŸå¤±è®¡ç®—å™¨
**æ–‡ä»¶**ï¼š`defense/nsr_loss.py`  
**å­¦æœ¯æ¥æº**ï¼šMa & Liang 2022, Eq.(7)  
**æ ¸å¿ƒå…¬å¼**ï¼š
$$L_{NSR} = (z_y-1)^2 + \sum_{i\neq y}(z_i-0)^2 + \sum_{i\neq y}\max(0,1-z_y+z_i) + \beta \cdot \log(R+1)$$
å…¶ä¸­ $R = \frac{\|w_y\|_1 \cdot \epsilon}{|z_y|}$

```python
class NSRLoss(nn.Module):
    def __init__(self, beta=0.4, eps=0.05, num_classes=5):
        super().__init__()
        self.beta = beta      # æ­£åˆ™åŒ–ç³»æ•°ï¼ŒMIT-BIHä¸Šæœ€ä½³0.4
        self.eps = eps        # ä½¿ç”¨Layer 1éªŒè¯çš„0.05
        self.num_classes = num_classes
        self.mse = nn.MSELoss()
    
    def forward(self, model, x, y, output):
        batch_size = y.size(0)
        
        # 1. MSE Loss (One-hotç›®æ ‡)
        y_onehot = F.one_hot(y, self.num_classes).float()
        mse_loss = self.mse(output, y_onehot)
        
        # 2. Margin Loss (ä»…å¯¹æ­£ç¡®åˆ†ç±»æ ·æœ¬)
        z_y = output[range(batch_size), y]
        margins = torch.clamp(1 - z_y.unsqueeze(1) + output, min=0)
        margins[range(batch_size), y] = 0
        margin_loss = margins.sum() / batch_size
        
        # 3. NSR Regularization (å…³é”®éƒ¨åˆ†)
        # è®¡ç®— ||w_y||_1ï¼šå¯¹ç±»åˆ«yçš„logitå…³äºè¾“å…¥xçš„æ¢¯åº¦çš„L1èŒƒæ•°
        w_l1 = torch.zeros(batch_size, device=x.device)
        for i in range(batch_size):
            xi = x[i:i+1].clone().detach().requires_grad_(True)
            out = model(xi)
            z = out[0, y[i]]
            grad = torch.autograd.grad(z, xi, create_graph=True)[0]
            w_l1[i] = torch.norm(grad, p=1)
        
        # è®¡ç®— R = ||w_y||_1 * eps / |z_y|
        R = (w_l1 * self.eps) / (torch.abs(z_y) + 1e-8)
        nsr_loss = self.beta * torch.mean(torch.log(R + 1))
        
        # 4. ç»„åˆï¼ˆä»…å¯¹æ­£ç¡®åˆ†ç±»æ ·æœ¬åº”ç”¨NSRå’ŒMarginï¼‰
        pred = output.argmax(dim=1)
        correct_mask = (pred == y).float().mean()
        
        total_loss = mse_loss + (margin_loss + nsr_loss) * correct_mask
        return total_loss, {
            'mse': mse_loss.item(),
            'margin': margin_loss.item(),
            'nsr': nsr_loss.item()
        }
```

### Task 2.5 NSRè®­ç»ƒç®¡é“
**æ–‡ä»¶**ï¼š`defense/train_nsr.py`  
**å…³é”®å·®å¼‚**ï¼šä½¿ç”¨NSRLossæ›¿ä»£CrossEntropyï¼Œeps=0.05

```python
# è®­ç»ƒé…ç½®
criterion = NSRLoss(beta=0.4, eps=0.05)  # åŸºäºLayer 1çš„eps
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# å»¶è¿Ÿå¯åŠ¨NSRï¼ˆå‰10epochåªç”¨MSEï¼Œé˜²æ­¢åˆæœŸæ¢¯åº¦çˆ†ç‚¸ï¼‰
for epoch in range(50):
    if epoch < 10:
        criterion.beta = 0  # å…³é—­NSR
    else:
        criterion.beta = 0.4  # å¼€å¯NSR
    
    train_epoch(...)
```

**è¶…å‚æ•°æœç´¢**ï¼ˆå¿…é¡»åšï¼‰ï¼š
- Betaå€™é€‰å€¼ï¼š[0.2, 0.4, 0.6, 0.8, 1.0]
- è¯„ä¼°æŒ‡æ ‡ï¼šACC_robust = sqrt(ACC_clean * AUC_under_attack)
- é€‰æ‹©éªŒè¯é›†ä¸ŠACC_robustæœ€é«˜çš„beta

---

## æ¨¡å—9ï¼šèåˆæ–¹æ¡ˆï¼ˆAT + NSRï¼‰

### Task 2.6 è”åˆè®­ç»ƒ (AT + NSR)
**æ–‡ä»¶**ï¼š`defense/train_at_nsr.py`  
**ç­–ç•¥**ï¼šå¯¹æŠ—è®­ç»ƒ + NSRæ­£åˆ™åŒ–åŒé‡é˜²æŠ¤

```python
def train_combined(model, loader, optimizer, eps=0.05, beta=0.4):
    for x_clean, y in loader:
        # 1. ç”Ÿæˆå¯¹æŠ—æ ·æœ¬ï¼ˆATéƒ¨åˆ†ï¼‰
        attacker = PGD(model, eps=eps, steps=10)
        x_adv = attacker.generate(x_clean, y)
        
        # 2. æ··åˆæ•°æ®
        x_mixed = torch.cat([x_clean, x_adv], dim=0)
        y_mixed = torch.cat([y, y], dim=0)
        
        # 3. ä½¿ç”¨NSR Lossï¼ˆæ›¿ä»£æ ‡å‡†CEï¼‰
        output = model(x_mixed)
        loss, loss_dict = nsr_criterion(model, x_mixed, y_mixed, output)
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
```

---

## æ¨¡å—10ï¼šé˜²å¾¡è¯„ä¼°ç³»ç»Ÿ

### Task 2.7 é²æ£’æ€§è¯„ä¼°æ¡†æ¶
**æ–‡ä»¶**ï¼š`evaluation/defense_eval.py`  
**è¯„ä¼°æ ‡å‡†**ï¼šå¯¹æ¯”Cleanæ¨¡å‹ vs é˜²å¾¡æ¨¡å‹åœ¨ç›¸åŒæ”»å‡»ä¸‹çš„è¡¨ç°

```python
def evaluate_robustness(model, test_loader, eps=0.05):
    results = {}
    
    # æµ‹è¯•æ”»å‡»ï¼ˆä½¿ç”¨Layer 1çš„attacksï¼Œeps=0.05ï¼‰
    attacks = {
        'clean': lambda x, y: (x, y),
        'fgsm': FGSM(model, eps),
        'pgd20': PGD(model, eps, steps=20),    # è¯„ä¼°ç”¨20æ­¥
        'pgd100': PGD(model, eps, steps=100),  # å¼ºæ”»å‡»
        'sap': SAP(model, eps, steps=40)
    }
    
    for name, attacker in attacks.items():
        correct = 0
        total = 0
        
        for x, y in test_loader:
            x, y = x.cuda(), y.cuda()
            if name == 'clean':
                x_adv = x
            else:
                x_adv = attacker.generate(x, y)
            
            with torch.no_grad():
                pred = model(x_adv).argmax(dim=1)
                correct += (pred == y).sum().item()
                total += y.size(0)
        
        results[name] = 100.0 * correct / total
    
    return results
```

**é¢„æœŸç»“æœå¯¹æ¯”è¡¨**ï¼ˆç›®æ ‡ï¼‰ï¼š

| æ¨¡å‹ | Clean | FGSM | PGD-20 | PGD-100 | SAP | ACC_robust |
|------|-------|------|--------|---------|-----|------------|
| **Clean** (Layer 1) | 93.4% | 8.3% | 11.5% | 1.8% | ~10% | ~0.35 |
| **Standard AT** | 88.0% | 75% | 65% | 45% | 60% | ~0.70 |
| **NSR (Î²=0.4)** | 90.5% | 70% | 72% | 55% | 80% | ~0.75 |
| **AT+NSR** | 87.0% | 78% | 75% | 60% | 82% | ~0.78 |

**ACC_robustè®¡ç®—**ï¼ˆåŸºäºMaè®ºæ–‡ï¼‰ï¼š
```python
def compute_acc_robust(clean_acc, adv_accuracies):
    """å‡ ä½•å¹³å‡ï¼šsqrt(clean_acc * mean(adv_accuracies))"""
    import numpy as np
    return np.sqrt(clean_acc * np.mean(adv_accuracies))
```

### Task 2.8 è¶…å‚æ•°è°ƒä¼˜è„šæœ¬
**æ–‡ä»¶**ï¼š`experiments/tune_beta.py`  
**åŠŸèƒ½**ï¼šè‡ªåŠ¨åŒ–æœç´¢æœ€ä½³betaå€¼ï¼ˆNSRï¼‰å’Œè®­ç»ƒç­–ç•¥

```bash
python experiments/tune_beta.py \
    --betas 0.2 0.4 0.6 0.8 1.0 \
    --eps 0.05 \
    --epochs 50
```

---

## ğŸ“¤ Layer 2 äº¤ä»˜æ£€æŸ¥æ¸…å•

å®Œæˆä»¥ä¸‹æ£€æŸ¥åï¼Œè¿›å…¥Layer 3ï¼ˆç‰¹å¾èåˆï¼‰ï¼š

- [ ] **é‡æ–°ç”Ÿæˆeps=0.05å¯¹æŠ—æ ·æœ¬**ï¼š`data/adversarial/eps005/`ç›®å½•å­˜åœ¨3ä¸ª.ptæ–‡ä»¶
- [ ] **Standard ATè®­ç»ƒå®Œæˆ**ï¼š`checkpoints/adv_standard_at.pth`ï¼ŒClean Accâ‰¥88%ï¼ŒPGD-20â‰¥60%
- [ ] **NSRè®­ç»ƒå®Œæˆ**ï¼š`checkpoints/nsr_beta0.4.pth`ï¼ŒACC_robustâ‰¥0.75
- [ ] **è¶…å‚æ•°æœç´¢å®Œæˆ**ï¼š`results/beta_tuning_results.json`ï¼Œç¡®å®šæœ€ä½³beta
- [ ] **å¯¹æ¯”å®éªŒå®Œæˆ**ï¼šç”Ÿæˆå¯¹æ¯”è¡¨æ ¼ï¼ˆClean vs AT vs NSR vs AT+NSRï¼‰
- [ ] **é²æ£’æ€§æ›²çº¿**ï¼šç»˜åˆ¶Accuracy vs Epsilonæ›²çº¿ï¼ˆeps=0~0.1ï¼‰

---

## ğŸ”— ä¸Layer 3çš„è¡”æ¥ï¼ˆé¢„è§ˆï¼‰

Layer 3å°†ä½¿ç”¨Layer 2è®­ç»ƒå¥½çš„**é²æ£’æ¨¡å‹**ï¼ˆå¦‚NSRæ¨¡å‹ï¼‰ä½œä¸ºç‰¹å¾æå–å™¨ï¼Œç»“åˆäººå·¥ç‰¹å¾ï¼ˆneurokit2æå–çš„RRé—´æœŸç­‰ï¼‰æ„å»ºåŒåˆ†æ”¯æ£€æµ‹å™¨ã€‚å› æ­¤Layer 2çš„æ¨¡å‹æƒé‡æ˜¯Layer 3çš„è¾“å…¥ã€‚

**å…³é”®ç»§æ‰¿ç‚¹**ï¼š
- Layer 2çš„`checkpoints/nsr_beta0.4.pth`å°†ä½œä¸ºLayer 3çš„`deep_branch`é¢„è®­ç»ƒæƒé‡
- Layer 2çš„`evaluate_robustness`å‡½æ•°å°†ç”¨äºéªŒè¯èåˆåçš„é˜²å¾¡æ•ˆæœ

---

**é¢„è®¡è€—æ—¶**ï¼š12-16å¤©ï¼ˆ5060æ˜¾å¡ï¼Œå«è¶…å‚æ•°æœç´¢ï¼‰  
**å…³é”®ä¾èµ–**ï¼šå¿…é¡»ä½¿ç”¨**eps=0.05**ï¼ˆåŸºäºLayer 1éªŒè¯çš„æœ‰æ•ˆæ”»å‡»å¼ºåº¦ï¼‰