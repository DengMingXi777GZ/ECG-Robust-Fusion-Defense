# 学习笔记：联邦学习中基于对抗训练的 ECG 分类鲁棒性提升

[[Mitigating Adversarial Attacks on ECG Classification in Federated Learning via Adversarial Training[.pdf#page=1&selection=7,0,9,11|Mitigating Adversarial Attacks on ECG Classification in Federated Learning via Adversarial Training[, 页面 1]]

> **论文**：Mitigating Adversarial Attacks on ECG Classification in Federated Learning via Adversarial Training
> **核心贡献**：提出 FAT（Federated Adversarial Training）框架，在联邦学习场景下通过客户端本地对抗训练，实现隐私保护与模型鲁棒性的双重保障。

---

## 1. 研究背景与问题定义 (Motivation)

### 1.1 联邦学习 (Federated Learning) 的工程定位

联邦学习是一种**分布式机器学习范式**，其核心特征是"数据不动、模型动"：

* **架构**：多个客户端（如不同医院）各自持有本地数据，仅将模型参数（而非原始数据）加密上传至中心服务器进行聚合。
* **适用领域**：医疗（跨院联合建模）、金融（跨机构风控）等数据严格合规的场景。
* **工程价值**：打破单一机构样本量不足的瓶颈，在不违反数据隐私法规（如 HIPAA、GDPR）的前提下，利用多源数据联合训练更强大的通用模型。

### 1.2 安全威胁：对抗攻击对联邦 ECG 模型的影响

深度学习模型对输入空间中的微小扰动极其敏感。在联邦学习场景下，这一问题更加严峻：

* **攻击面扩大**：模型参数在通信过程中可能被截获，攻击者可据此构造白盒对抗样本。
* **医疗后果严重**：ECG 分类错误可能导致漏诊房颤、室速等致命心律失常，直接危及生命。
* **防御缺口**：标准联邦学习（FedAvg）仅优化干净数据上的经验风险，**无法自然产生对抗鲁棒性**。

### 1.3 本文解决方案：FAT (Federated Adversarial Training)

**核心思想**：将对抗训练"下沉"到联邦学习的客户端本地训练阶段。每个客户端在本地动态生成对抗样本，与原始数据混合训练，使模型在参数聚合前就具备初步的攻击抵抗能力。

---

## 2. 理论基础：对抗攻击方法体系 (Attack Taxonomy)

本文采用四种经典对抗攻击方法进行训练和评估。从优化理论视角，它们本质上都在求解同一个核心问题：**在扰动幅度约束内，最大化模型预测误差**。

### 2.1 基于梯度的攻击（用于训练 + 测试）

#### FGSM (Fast Gradient Sign Method)
最简单的单步攻击，作为鲁棒性评估的基线：

$$ x_{adv} = x + \epsilon \cdot \text{sgn}(\nabla_x L(\theta, x, y)) $$

* **特点**：计算开销极低（仅一次前向 + 反向传播），但攻击精度有限。
* **文献配置**：$\epsilon = 8/255$，仅用于测试。

#### BIM (Basic Iterative Method / I-FGSM)
FGSM 的迭代增强版本，通过多步小幅扰动提升攻击强度：

$$ x_{t+1} = \text{clip}_{x, \epsilon}\left(x_t + \alpha \cdot \text{sgn}(\nabla_x L(\theta, x_t, y))\right) $$

* **文献配置**：$\epsilon = 8/255$，步长 $\alpha = 2/255$，迭代 10 次。

#### PGD (Projected Gradient Descent)  训练核心
PGD 是 BIM 的增强版，引入**随机初始化**以跳出局部最优，被广泛视为评估 $L_\infty$ 鲁棒性的标准方法：

$$ x_{t+1} = \Pi_{\mathcal{B}(x, \epsilon)}\left(x_t + \alpha \cdot \text{sgn}(\nabla_x L(\theta, x_t, y))\right), \quad x_0 \sim \mathcal{U}(\mathcal{B}(x, \epsilon)) $$

* **文献配置**：$\epsilon = 8/255$，步长 $\alpha = 1/255$，迭代 20 次。
* **关键角色**：既是 FAT 中生成训练对抗样本的攻击源，也是测试阶段的主要评估工具。

### 2.2 基于优化的攻击（仅用于测试）

#### CW (Carlini & Wagner)  极限压力测试
与上述梯度方法**本质不同**：CW 将攻击建模为一个**约束优化问题**，不直接最大化损失，而是寻找**最小有效扰动**：

$$ \min_{\delta} \|\delta\|_p + c \cdot f(x + \delta) $$

其中 $f(\cdot)$ 为设计的目标函数，当 $x+\delta$ 被错误分类时趋近于 0。

* **文献配置**：置信度 $c = 1$，$\kappa = 0$，优化步数 50，学习率 0.01（Adam 优化器）。
* **工程意义**：CW 是"终极 Boss"级攻击PGD 是暴力搜索让模型出错的方向，CW 则智能地寻找决策边界的最薄弱点。

### 2.3 PGD vs CW：关键差异总结

| 维度 | PGD | CW |
| :--- | :--- | :--- |
| **优化目标** | 最大化模型损失 $L$ | 最小化扰动幅度 $\|\delta\|$ |
| **核心逻辑** | "怎么改让模型错最惨" | "最少改多少就能骗过模型" |
| **求解器** | 一阶梯度上升 + 投影 | Adam 等高阶优化器 |
| **计算开销** | 中等 | 较高 |
| **攻击隐蔽性** | 一般 | 极强（扰动更小更精准） |
| **防御难度** | FAT 可防至 95% | FAT 仅防至 47% |
| **工程用途** | 适合做训练攻击源 | 适合做极限压力测试 |

---

## 3. FAT 算法架构与实现 (Algorithm Design)

### 3.1 宏观架构：Client-Server 模式

FAT 遵循标准联邦学习通信协议，**创新点集中在客户端训练逻辑**：

* **Server（服务器）**：
  * 分发全局模型参数 $\hat{\theta}$
  * 聚合各客户端返回的本地参数（FedAvg 加权平均）
  * $$ \hat{\theta} \leftarrow \sum_{i \in S} \frac{n_i}{m} \theta_i $$
  * 其中 $n_i$ 为客户端 $i$ 的数据量，$m = \sum n_i$ 为参与本轮训练的总数据量

* **Client（客户端）**：
  * 接收全局参数  本地对抗训练  回传更新后的鲁棒参数
  * **核心改造**：在标准本地 SGD 中引入 PGD 对抗样本增强

### 3.2 客户端本地训练流程（Algorithm 1 逐步解析）

**输入**：全局参数 $\hat{\theta}$，本地数据 $D_i$，本地轮数 $E$，批大小 $b$，学习率 $\eta$

```
1. θ_i  θ                          // 初始化为全局参数
2. for epoch = 1 to E do              // 本地多轮训练
3.   for mini-batch {x_j, y_j} do     // 遍历本地数据
4.     x_j_adv  PGD(x_j, y_j; θ_i)  //  生成对抗样本
5.     x_j  concat(x_j, x_j_adv)    // 拼接原始 + 对抗数据
6.     ŷ_j  concat(y_j, y_j)         // 标签复制（真实类别不变）
7.     θ_i  θ_i - ηL_CE(x_j, ŷ_j; θ_i)  // 混合数据更新参数
8.   end for
9. end for
10. return θ_i                         // 返回鲁棒化参数
```

**关键步骤解读**：

| 步骤 | 操作 | 原理与工程意义 |
| :--- | :--- | :--- |
| **Step 4** | PGD 生成 $x_j^{adv}$ | 利用当前模型梯度，在 $\epsilon$-球内搜索最坏情况输入。这是 Min-Max 博弈的**内层最大化** |
| **Step 5-6** | 数据拼接 | 等价于一种**在线数据增强**增强的不是随机噪声，而是最具对抗性的"高难度"样本 |
| **Step 7** | 混合梯度更新 | 模型被迫在干净样本和对抗样本上同时降低损失，即 Min-Max 的**外层最小化**。模型学到的特征必须对微小扰动不敏感 |

**隐含的 Min-Max 博弈结构**：

$$ \min_{\theta_i} \mathbb{E}_{(x,y) \sim D_i} \left[ L_{CE}(f_{\theta_i}(x), y) + L_{CE}(f_{\theta_i}(x + \delta^*), y) \right], \quad \delta^* = \arg\max_{\|\delta\|_\infty \le \epsilon} L_{CE}(f_{\theta_i}(x+\delta), y) $$

---

## 4. 实验设计与评价 (Experimental Protocol)

### 4.1 数据与模型配置

| 配置项 | 设置 | 评价 |
| :--- | :--- | :--- |
| **数据集** | MIT-BIH Arrhythmia Database | 心律失常分类"金标准"，学术认可度高 |
| **预处理** | R 波中心截取 180 点，Min-Max 归一化至 $[0,1]$ | 标准化流程，利于复现 |
| **数据规模** | 109,468 窗口，80/20 划分 | 规模适中 |
| **模型** | 4 层 CNN（约 41 万参数） | 轻量级，适合联邦环境，聚焦算法验证 |
| **联邦参数** | 10 客户端，每轮随机选 5 个，本地 5 epochs | 规模偏小，适合概念验证 |
| **评估指标** | Accuracy, Precision, Recall, F1 | 多维度评估，对医疗场景尤为重要 |

### 4.2 实验设计的亮点

1. **攻击多样性验证**：训练仅用 PGD，测试覆盖 PGD/FGSM/BIM/CW 四种攻击，验证了防御的**迁移泛化性**。
2. **白盒假设**：假设攻击者完全知晓模型架构与参数，这是安全评估的最严格标准。
3. **指标选择**：引入 Precision/Recall，而非仅依赖 Accuracy在类别不平衡的医疗数据中，Recall（漏诊率）和 Precision（误诊率）对临床可信度至关重要。

### 4.3 实验设计的局限

1. **数据划分风险**：未明确说明是否按**患者级别 (Patient-Level)** 划分。若按心拍随机划分，同一患者的数据可能同时出现在训练集和测试集中，导致 **Data Leakage**，性能虚高。
2. **IID 假设**：10 个客户端均匀分配数据，假设为 IID 分布。真实场景中各医院病种分布高度不均（Non-IID），对抗训练在 Non-IID 下可能面临"鲁棒性发散"问题。
3. **通信轮次偏少**：仅 10 轮全局聚合，不足以观察长期训练的稳定性与鲁棒性是否退化。

---

## 5. 实验结果深度分析 (Empirical Analysis)

### 5.1 核心结果：鲁棒性的质变

| 攻击方法 | Non-FAT Accuracy | FAT Accuracy | 提升幅度 | 防御评级 |
| :--- | :--- | :--- | :--- | :--- |
| 无攻击（Clean） | 98.44% | 97.60% | -0.84% |  |
| **PGD** | 35.14% | **94.82%** | **+59.68%** | 优秀 |
| **FGSM** | 73.87% | **95.44%** | +21.57% | 优秀 |
| **BIM** | 35.36% | **94.81%** | **+59.45%** | 优秀 |
| **CW** | 7.47% | **46.65%** | +39.18% | 有限 |

**关键洞察**：
* FAT 在 PGD/FGSM/BIM 攻击下均实现从"系统崩溃"（35%）到"高可用"（95%）的跨越式提升。
* CW 攻击仍是防御短板，暴露了仅用 $L_\infty$-PGD 训练的局限性。

### 5.2 鲁棒性-精度权衡 (Robustness-Accuracy Trade-off)

* **代价极小**：干净数据上仅损失 **0.84%** 的精度（98.44%  97.60%）。
* **收益巨大**：面对三种主流梯度攻击，防御成功率提升约 **60 个百分点**。
* **工程判断**：在医疗 AI 安全部署中，这不到 1% 的精度损失是一笔极其划算的"安全保险费"。

### 5.3 临床可信度指标分析

以 PGD 攻击为例：

| 指标 | Non-FAT（被攻击后） | FAT（被攻击后） | 临床意义 |
| :--- | :--- | :--- | :--- |
| **Recall** | 21.27% | **80.13%** | 漏诊率从 79% 降至 20% |
| **Precision** | 30.12% | **81.72%** | 误诊率大幅下降 |
| **F1** | 24.82% | **80.26%** | 综合诊断能力恢复 |

**工程解读**：Non-FAT 模型在攻击下 Recall 仅 21%，意味着每 5 个真实阳性患者中约有 4 个被漏诊这在临床上是不可接受的。FAT 将 Recall 恢复至 80% 以上，使模型具备了基本的临床可用性。

### 5.4 迁移防御能力分析

FAT 仅用 PGD 作为训练攻击源，却在 FGSM/BIM 上也达到 95% 的防御效果：

* **原因**：FGSM/BIM/PGD 同属基于 $L_\infty$ 梯度的攻击族，共享相似的扰动子空间。FAT 通过对抗 PGD（该族中最强的攻击），学到了对整个攻击族的免疫力。
* **CW 防御不足的原因**：CW 的优化目标根本不同（最小化扰动而非最大化损失），其生成的对抗样本位于决策边界的"更薄弱"区域，PGD 式训练难以覆盖。
* **改进方向**：可在训练中引入 CW 作为额外攻击源，或采用 TRADES 等更先进的对抗训练框架。

### 5.5 收敛行为分析

* FAT 模型通常在第 2 轮全局聚合后即快速收敛并保持高鲁棒性。
* Non-FAT 模型无论训练多少轮，在对抗数据上始终表现极差，**印证了"鲁棒性无法通过标准训练自然涌现"的理论判断**。

---

## 6. 工程启示与架构建议 (Engineering Implications)

### 6.1 FAT 的工程本质

从系统工程视角，FAT 可被理解为三种范式的融合：

1. **防御前置 (Shift-Left Security)**：将安全防御从部署后的被动响应，前移至训练阶段的主动免疫。
2. **在线数据增强 (Online Augmentation)**：对抗样本可视为一种特殊的"最坏情况增强"普通增强是随机变换，FAT 的增强是针对性的对抗扰动。
3. **隐私-安全双保障**：原始数据 $x_j$ 和对抗样本 $x_j^{adv}$ 始终留在本地，上传的仅是模型参数，同时满足 FL 隐私约束和 AT 鲁棒需求。

### 6.2 计算与通信开销分析

| 维度 | 影响 | 量化估计 |
| :--- | :--- | :--- |
| **客户端计算** | 显著增加（每 batch 需多跑一遍 PGD 迭代） | 训练时间增加约 2-3 倍 |
| **通信开销** | 无额外增加（传输的仍是模型参数） | 与标准 FL 一致 |
| **存储需求** | 略增（需缓存对抗样本） | Batch 级别，可忽略 |

### 6.3 部署建议

1. **攻击源多样化**：训练时不仅用 PGD，建议混合 CW 或 AutoAttack，以覆盖更广的攻击子空间。
2. **Non-IID 适配**：真实部署前需在 Non-IID 数据分布下验证 FAT 的收敛性与鲁棒性稳定性。
3. **Patient-Level 划分**：严格按患者划分训练/测试集，避免数据泄露带来的评估偏差。
4. **资源调度**：对于计算资源有限的客户端（如边缘设备），可考虑 Free AT / FGSM-AT 等轻量级对抗训练替代方案。

### 6.4 技术栈参考

* **深度学习框架**：PyTorch
* **联邦学习框架**：Flower（工业级 FL 框架，支持异构客户端）
* **攻击工具库**：Torchattacks（提供 FGSM/PGD/CW/BIM 等标准攻击实现）

---

## 7. 总结

**FAT 的核心价值**：在联邦学习的隐私约束下，以不到 1% 的干净精度损失为代价，将模型在主流对抗攻击下的生存能力从 35% 提升至 95%。

**方法边界**：对基于优化的强攻击（CW）防御仍有限（47%），暴露了单一攻击源训练的覆盖不足。

**一句话总结**：每个客户端在本地训练时不仅当"学生"，还要充当"考官"利用 PGD 给自己出难题，迫使模型不仅答对简单题，还要答对精心设计的陷阱题，最终所有客户端的"抗坑"能力在服务器端汇聚成一个全局鲁棒模型。
