# 学习笔记：利用对抗训练提升心电图 (ECG) 自动分类模型的迁移性与鲁棒性[[CinC2024-096.pdf#page=1&selection=0,0,1,44|CinC2024-096, 页面 1]]

## 1. 研究背景与工程痛点 (Motivation & Problem Definition)

### 1.1 核心挑战：域偏移 (Domain Shift)
在医疗 AI 落地工程中，最大的障碍之一是模型在不同临床场景下的泛化能力。
* **数据分布不一致**：在 A 医院录制的数据上训练的模型，部署到 B 医院（使用不同设备、采样率不同、患者人群 demographics 差异）时，性能往往会大幅下降。
* **标注成本高昂**：ECG 信号的专家标注需要极高的专业知识与时间成本，每个新场景下都重新收集海量标注数据（n > 10,000）进行从头训练是不现实的。

### 1.2 解决方案探索
* **常规路径 (Transfer Learning)**：基于大规模公共数据集（如 PTB-XL）进行预训练，然后在目标域小数据集上进行微调。
* **本文核心思路**：通过**对抗训练 (Adversarial Training)** 获取具有更强特征表达能力的预训练权重。作者假设，对抗鲁棒的模型能学到生理本质相关的核心特征，而非仅仅捕捉当前数据集中的虚假相关性（Shortcuts），从而提升迁移效率。

## 2. 对抗训练的理论框架 (Theoretical Foundations)

### 2.1 优化目标：Min-Max 博弈
对抗训练将传统的风险最小化问题转化为一个鲁棒优化问题，其本质是模型 $\theta$ 与扰动 $\delta$ 之间的博弈：

$$ \min_{\theta} \mathbb{E}_{(x,y) \sim D} \left[ \max_{\|\delta\|_p \le \epsilon} L(f_\theta(x + \delta), y) \right] $$

* **内层最大化 (Attack)**：寻找在限制范围 $S$ 内（$\|\delta\|_\infty \le \epsilon$）能使模型损失函数 $L$ 最大化的最坏情况样本。
* **外层最小化 (Defense)**：通过梯度下降更新参数 $\theta$，使模型在所有微扰样本下依然能保持正确的预测。

### 2.2 攻击算法演进：从 PGD 到 APGD
* **PGD (Projected Gradient Descent)**：一种迭代式的攻击方法，通过多次计算梯度并进行投影操作：
  $$ x_{t+1} = \Pi_{S}(x_t + \alpha \cdot \text{sgn}(\nabla_x L(x_t, y))) $$
* **APGD (Auto-PGD)**：PGD 的自适应版本，其改进点在于：
  1. **自适应步长**：根据损失下降的情况动态调整学习率，避免陷入震荡或局部最优。
  2. **动量机制**：引入前一步的梯度信息，加速搜索。
  * **工程意义**：APGD 比 PGD 更能稳定地搜索到全局或更高强度的对抗样本，是目前评估模型鲁棒性的 SOTA 方法。

## 3. 工程实现逻辑 (Engineering Implementation)

### 3.1 实验方案设计
* **源域 (Source Domain)**：**PTB-XL** 数据集（约 21,000 条 12 导联信号）。
* **目标域 (Target Domain)**：**CODE-15%** 巴西远程医疗数据集。
* **模型架构**：**一维残差网络 (1D ResNet)**。
  * 输入：重采样至 400Hz，固定长度 4096 点。
  * 这种架构类似于 ResNet-34 经过 1D 改造，是处理 ECG 序列的标准 SOTA 方案。

### 3.2 训练策略的关键细节
为了平衡性能、稳定性和计算效率，工程实现采用了以下技巧：
1. **两阶段预热 (Pre-warming)**：先用干净数据训练 10 epochs。若直接开始对抗训练，模型难以从噪声中学习到有用的生理形态，导致无法收敛。
2. **混合损失函数 (Mixed Training)**：
   $$ Loss_{total} = \frac{1}{2} (Loss_{clean} + Loss_{adversarial}) $$
   同时拟合原始样本和对抗样本，有助于维持模型在干净数据上的性能（Clean Accuracy）。
3. **扰动强度调度 (Epsilon Scheduling)**：
   * 采用指数增长策略（Exponential Schedule）控制 $\epsilon$。
   * 这种由易到难的策略类似于课程学习（Curriculum Learning），能显著提高训练稳定性。

## 4. 实验结果与深度分析 (Empirical Analysis)

### 4.1 迁移性能与数据效率
实验中最具价值的发现在于对抗训练对**迁移学习**的显著增强：

| 训练配置 | 目标域数据量 | 迁移效果 (AUPRC) | 结论 |
| :--- | :--- | :--- | :--- |
| **Baseline (从头训练)** | 90% CODE-15% | 0.685 | 对标基准 |
| 标准模型微调 | 10% CODE-15% | 0.685 | 持平基准，无额外增益 |
| **对抗模型预训练 ($\epsilon=0.05$)** | **10% CODE-15%** | **0.732** | **大幅超越基准** |

**洞察 (Insights)**：对抗训练模型仅使用 **1/9** 的下游数据，就超越了标准模型在全量数据上的表现。这证明了对抗训练学到的特征具有极高的信息密度和泛化潜能。

### 4.2 鲁棒性与精度之间的权衡 (Trade-off)
* **牺牲项**：对抗强度 $\epsilon$ 越大，模型在干净数据上的精度（Standard Accuracy）会有轻微下降。
* **工程判断**：在实际跨设备部署中，这种精度微降是可接受的，因为模型的泛化能力（适应新环境的能力）才是决定商用成败的关键。

## 5. 工程启示与落地建议 (Synthesis & Conclusion)

1. **构建超级稳健的基础模型**：
   在资源允许的情况下，ECG 领域的大规模预训练不应只追求精度，引入对抗训练（即使是轻微的扰动）可以消除信号采集过程中的设备指纹和环境噪声噪声，促使模型学习真正的波形形态特征。

2. **多源协同微调策略**：
   对于新客户的窄域部署项目，建议优先选择在对抗环境下预训练的模型。微调时采用低学习率（Low LR）策略，重点调整全连接层（Classification Head），保留对抗训练带来的鲁棒特征。

3. **算力时间权衡**：
   对抗训练的计算开销增加了约 2-2.5 倍（因需多次反向传播计算攻击梯度）。但在工程交付中，这种一次性的训练成本换取后端数据采集、标注成本的数十倍降低，具有极高的 ROI。

---

**一句话总结**：
对抗训练不再仅仅是盾牌，它更是提升模型跨域生存能力的催化剂。通过逼迫模型忽略脆弱特征，我们获得了一套能在多变医疗环境下稳定工作的老专家经验。
